{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_4-77xHk44"
   },
   "source": [
    "# **Import Some Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# For data preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtE3b6JEH7rw"
   },
   "source": [
    "# **Some Utilities**\n",
    "\n",
    "You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['mean_train_loss'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['mean_train_loss']) // len(loss_record['mean_valid_loss'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['mean_train_loss'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['mean_valid_loss'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(10e+2,5*10e+5)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)\n",
    "\n",
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(device)                        \n",
    "        with torch.no_grad():                   \n",
    "            pred = model(x)                     \n",
    "            preds.append(pred.detach().cpu())   \n",
    "    preds = torch.cat(preds, dim=0).numpy()  \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_data = pd.read_csv('../LiterallyWikidata/files_needed/train_attri_data_minmax.csv')\n",
    "attri_data_valid = pd.read_csv('../LiterallyWikidata/files_needed/valid_attri_data_minmax.csv')\n",
    "attri_data_test = pd.read_csv('../LiterallyWikidata/files_needed/test_attri_data_minmax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>v</th>\n",
       "      <th>name_e</th>\n",
       "      <th>name_a</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>minmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3376</td>\n",
       "      <td>P1334_Latitude</td>\n",
       "      <td>4.606556e+01</td>\n",
       "      <td>Trento</td>\n",
       "      <td>coordinates of easternmost point</td>\n",
       "      <td>Q747074</td>\n",
       "      <td>6.978149e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q170446</td>\n",
       "      <td>P1082</td>\n",
       "      <td>1.094284e+06</td>\n",
       "      <td>Sumy Oblast</td>\n",
       "      <td>population</td>\n",
       "      <td>Q3348196</td>\n",
       "      <td>2.627804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q908156</td>\n",
       "      <td>P625_Latitude</td>\n",
       "      <td>3.821420e+01</td>\n",
       "      <td>Namboku Line</td>\n",
       "      <td>coordinate location(latitude)</td>\n",
       "      <td>Q15079663</td>\n",
       "      <td>7.123011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q423</td>\n",
       "      <td>P1332_Longtiude</td>\n",
       "      <td>1.299300e+02</td>\n",
       "      <td>North Korea</td>\n",
       "      <td>coordinates of northernmost point</td>\n",
       "      <td>Q6256</td>\n",
       "      <td>8.688086e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q611033</td>\n",
       "      <td>P2048</td>\n",
       "      <td>1.730000e+00</td>\n",
       "      <td>Jos√© Antonio Castro</td>\n",
       "      <td>height</td>\n",
       "      <td>Q5</td>\n",
       "      <td>1.694772e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29626</th>\n",
       "      <td>Q1754</td>\n",
       "      <td>P571</td>\n",
       "      <td>1.187000e+03</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>inception</td>\n",
       "      <td>Q707813</td>\n",
       "      <td>7.204698e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29627</th>\n",
       "      <td>Q531135</td>\n",
       "      <td>P2067</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>Richard Witschge</td>\n",
       "      <td>mass</td>\n",
       "      <td>Q5</td>\n",
       "      <td>3.519147e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29628</th>\n",
       "      <td>Q1689057</td>\n",
       "      <td>P6546</td>\n",
       "      <td>2.680000e+02</td>\n",
       "      <td>Jim Campbell</td>\n",
       "      <td>penalty minutes in career</td>\n",
       "      <td>Q5</td>\n",
       "      <td>6.701940e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29629</th>\n",
       "      <td>Q46246</td>\n",
       "      <td>P2046</td>\n",
       "      <td>1.227000e+07</td>\n",
       "      <td>Cazzano di Tramigna</td>\n",
       "      <td>area</td>\n",
       "      <td>Q747074</td>\n",
       "      <td>2.014778e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29630</th>\n",
       "      <td>Q583267</td>\n",
       "      <td>P6509</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>Juha Lind</td>\n",
       "      <td>total goals in career</td>\n",
       "      <td>Q5</td>\n",
       "      <td>1.000000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29631 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              e                a             v               name_e  \\\n",
       "0         Q3376   P1334_Latitude  4.606556e+01               Trento   \n",
       "1       Q170446            P1082  1.094284e+06          Sumy Oblast   \n",
       "2       Q908156    P625_Latitude  3.821420e+01         Namboku Line   \n",
       "3          Q423  P1332_Longtiude  1.299300e+02          North Korea   \n",
       "4       Q611033            P2048  1.730000e+00  Jos√© Antonio Castro   \n",
       "...         ...              ...           ...                  ...   \n",
       "29626     Q1754             P571  1.187000e+03            Stockholm   \n",
       "29627   Q531135            P2067  7.000000e+01     Richard Witschge   \n",
       "29628  Q1689057            P6546  2.680000e+02         Jim Campbell   \n",
       "29629    Q46246            P2046  1.227000e+07  Cazzano di Tramigna   \n",
       "29630   Q583267            P6509  9.000000e+00            Juha Lind   \n",
       "\n",
       "                                  name_a   ent_type        minmax  \n",
       "0       coordinates of easternmost point    Q747074  6.978149e-01  \n",
       "1                             population   Q3348196  2.627804e-04  \n",
       "2          coordinate location(latitude)  Q15079663  7.123011e-01  \n",
       "3      coordinates of northernmost point      Q6256  8.688086e-01  \n",
       "4                                 height         Q5  1.694772e-04  \n",
       "...                                  ...        ...           ...  \n",
       "29626                          inception    Q707813  7.204698e-01  \n",
       "29627                               mass         Q5  3.519147e-29  \n",
       "29628          penalty minutes in career         Q5  6.701940e-02  \n",
       "29629                               area    Q747074  2.014778e-12  \n",
       "29630              total goals in career         Q5  1.000000e-02  \n",
       "\n",
       "[29631 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri_data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attri_data_valid=attri_data_valid[['e','a','v']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ê∫ñÂÇôËÆäÊï∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name=[\"population\",\"GDP (PPP)\",\"PPP GDP per capita\",\n",
    "      \"date of birth\",\"date of death\",\n",
    "      \"area\",\"work period (start)\",\"work period (end)\",\n",
    "      \"coordinate location(latitude)\",\"coordinate location(logtitude)\",\"height\"]\n",
    "list_var = ['P1082','P4010','P2299','P569','P570','P2046','P2031','P2032','P625_Latitude','P625_Longtiude','P2048']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_data['name_a'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making input data\n",
    "## ent --> pretrained; att-->initial emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áî®kgeembÈ†ÜÂ∫è\n",
    "ent2idx ={}\n",
    "with open('../LiterallyWikidata/files_needed/list_ent_ids.txt','r') as fr:\n",
    "    for i, word in enumerate(fr.readlines()):\n",
    "        ent2idx[word.strip()] = i\n",
    "\n",
    "#ÂÖàÁî®Ê≤íÊúâÊ®ôÊ∫ñÂåñ y \n",
    "#attri_data_std_v = attri_data[['e','a','new_stdv']]\n",
    "\n",
    "# att2idx = {}\n",
    "# #rel2idx = {v:k for k,v in enumerate(relations['label'].unique())}\n",
    "\n",
    "# with open('../LiterallyWikidata/files_needed/attribute.txt','r') as fr:\n",
    "#     for i, word in enumerate(fr.readlines()):\n",
    "#         att2idx[word.strip()] = i\n",
    "        \n",
    "att2idx = {v:k for k,v in enumerate(attri_data['a'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading pre-trained embedding\n",
    "emb_ent = torch.load('../LiterallyWikidata/files_needed/pretrained_kge/pretrained_complex_entemb.pt')\n",
    "embedding_e = torch.nn.Embedding.from_pretrained(emb_ent)\n",
    "# input_e = torch.LongTensor(attri_data['ent_idx'].to_numpy())\n",
    "# entity_embedding = embedding_e(input_e)*math.sqrt(2./128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_data['a_idx']=attri_data['a'].map(att2idx)\n",
    "attri_data['e_idx']=attri_data['e'].map(ent2idx)\n",
    "attri_data_valid['a_idx']=attri_data_valid['a'].map(att2idx)\n",
    "attri_data_valid['e_idx']=attri_data_valid['e'].map(ent2idx)\n",
    "# attri_data_test['a_idx']=attri_data_test['a'].map(att2idx)\n",
    "# attri_data_test['e_idx']=attri_data_test['e'].map(ent2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_data_train = attri_data[['e','a','v']]\n",
    "attri_data_valid = attri_data_valid[['e','a','v']]\n",
    "# attri_data_test = attri_data_test[['e','a','minmax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attri_valid_new = pd.concat([attri_data_valid,attri_data_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂÅöÁü©Èô£Ôºåent * attÔºå ‰∫§ÂèâÁÇ∫ÂÄº v\n",
    "def numeric_literal_array(data, ent2idx, att2idx):\n",
    "    #'LiterallyWikidata/LitWD48K/train_attri_data'\n",
    "    df_all = data\n",
    "\n",
    "    # Resulting file\n",
    "    num_lit = np.zeros([len(ent2idx), len(att2idx)],dtype=np.float32)\n",
    "\n",
    "# Create literal wrt vocab\n",
    "    for i, (s, p, lit) in enumerate(df_all.values):\n",
    "        try:\n",
    "            num_lit[ent2idx[s], att2idx[p]] = lit\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return num_lit\n",
    "\n",
    "\n",
    "# num_lit shape (47998, 86)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47998, 86) (47998, 86)\n"
     ]
    }
   ],
   "source": [
    "#vÂÄºÊ≤íÊúâÊ®ôÊ∫ñÂåñ\n",
    "num_lit = numeric_literal_array(attri_data_train, ent2idx, att2idx)\n",
    "\n",
    "num_lit_valid = numeric_literal_array(attri_data_valid, ent2idx, att2idx)\n",
    "print(num_lit.shape, num_lit_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue:ÂèØËÉΩÊúâÂæàÂ§öÁ©∫ÂÄº\n",
    "num_lit[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÂÄºÁî®Ê®ôÊ∫ñÂåñÁöÑ\n",
    "num_lit_stdv = numeric_literal_array(attri_data_std_v, ent2idx, att2idx)\n",
    "#print(num_lit_stdv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1082 3\n",
      "P4010 70\n",
      "P2299 46\n",
      "P569 9\n",
      "P570 20\n",
      "P2046 4\n",
      "P2031 7\n",
      "P2032 30\n",
      "P625_Latitude 0\n",
      "P625_Longtiude 1\n",
      "P2048 27\n"
     ]
    }
   ],
   "source": [
    "for i in list_var:\n",
    "    print(i,att2idx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## constraint needed:\n",
    "pop_idx = att2idx['P1082']\n",
    "#gdp = att2idx['P4010']\n",
    "#nominal_gdp = att2idx['P2131']\n",
    "# nominal_gdp_per = att2idx['P2132']\n",
    "#gdp_per = att2idx['P2299']\n",
    "date_of_birth = att2idx['P569']\n",
    "date_of_death = att2idx['P570']\n",
    "area = ['P2046']\n",
    "# work_start = att2idx['P2031']\n",
    "# work_end = att2idx['P2032']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>v</th>\n",
       "      <th>name_e</th>\n",
       "      <th>name_a</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>minmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223010</th>\n",
       "      <td>Q2766547</td>\n",
       "      <td>P2046</td>\n",
       "      <td>5.950000e+07</td>\n",
       "      <td>'s-Hertogenbosch</td>\n",
       "      <td>area</td>\n",
       "      <td>Q515</td>\n",
       "      <td>9.770115e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169212</th>\n",
       "      <td>Q2766547</td>\n",
       "      <td>P1082</td>\n",
       "      <td>1.437820e+05</td>\n",
       "      <td>'s-Hertogenbosch</td>\n",
       "      <td>population</td>\n",
       "      <td>Q515</td>\n",
       "      <td>3.452769e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122088</th>\n",
       "      <td>Q191066</td>\n",
       "      <td>P1082</td>\n",
       "      <td>2.333920e+05</td>\n",
       "      <td>15th arrondissement of Paris</td>\n",
       "      <td>population</td>\n",
       "      <td>Q702842</td>\n",
       "      <td>5.604656e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117129</th>\n",
       "      <td>Q191066</td>\n",
       "      <td>P2046</td>\n",
       "      <td>8.500000e+06</td>\n",
       "      <td>15th arrondissement of Paris</td>\n",
       "      <td>area</td>\n",
       "      <td>Q702842</td>\n",
       "      <td>1.395731e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223939</th>\n",
       "      <td>Q18890040</td>\n",
       "      <td>P2046</td>\n",
       "      <td>1.260000e+08</td>\n",
       "      <td>2015 Sampson Flat bushfires</td>\n",
       "      <td>area</td>\n",
       "      <td>Q1017324</td>\n",
       "      <td>2.068966e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159470</th>\n",
       "      <td>Q25797</td>\n",
       "      <td>P2046</td>\n",
       "      <td>8.003000e+07</td>\n",
       "      <td>≈Ωilina</td>\n",
       "      <td>area</td>\n",
       "      <td>Q6784672</td>\n",
       "      <td>1.314122e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215228</th>\n",
       "      <td>Q394453</td>\n",
       "      <td>P2046</td>\n",
       "      <td>3.706368e+07</td>\n",
       "      <td>≈Ωƒè√°r nad S√°zavou</td>\n",
       "      <td>area</td>\n",
       "      <td>Q8452914</td>\n",
       "      <td>6.085990e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56507</th>\n",
       "      <td>Q394453</td>\n",
       "      <td>P1082</td>\n",
       "      <td>2.071700e+04</td>\n",
       "      <td>≈Ωƒè√°r nad S√°zavou</td>\n",
       "      <td>population</td>\n",
       "      <td>Q8452914</td>\n",
       "      <td>4.974963e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31531</th>\n",
       "      <td>Q579648</td>\n",
       "      <td>P2046</td>\n",
       "      <td>1.578510e+09</td>\n",
       "      <td>≈Ωƒè√°r nad S√°zavou District</td>\n",
       "      <td>area</td>\n",
       "      <td>Q548611</td>\n",
       "      <td>2.591970e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>Q579648</td>\n",
       "      <td>P1082</td>\n",
       "      <td>1.181580e+05</td>\n",
       "      <td>≈Ωƒè√°r nad S√°zavou District</td>\n",
       "      <td>population</td>\n",
       "      <td>Q548611</td>\n",
       "      <td>2.837436e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34558 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                e      a             v                        name_e  \\\n",
       "223010   Q2766547  P2046  5.950000e+07              's-Hertogenbosch   \n",
       "169212   Q2766547  P1082  1.437820e+05              's-Hertogenbosch   \n",
       "122088    Q191066  P1082  2.333920e+05  15th arrondissement of Paris   \n",
       "117129    Q191066  P2046  8.500000e+06  15th arrondissement of Paris   \n",
       "223939  Q18890040  P2046  1.260000e+08   2015 Sampson Flat bushfires   \n",
       "...           ...    ...           ...                           ...   \n",
       "159470     Q25797  P2046  8.003000e+07                        ≈Ωilina   \n",
       "215228    Q394453  P2046  3.706368e+07              ≈Ωƒè√°r nad S√°zavou   \n",
       "56507     Q394453  P1082  2.071700e+04              ≈Ωƒè√°r nad S√°zavou   \n",
       "31531     Q579648  P2046  1.578510e+09     ≈Ωƒè√°r nad S√°zavou District   \n",
       "6381      Q579648  P1082  1.181580e+05     ≈Ωƒè√°r nad S√°zavou District   \n",
       "\n",
       "            name_a  ent_type        minmax  \n",
       "223010        area      Q515  9.770115e-12  \n",
       "169212  population      Q515  3.452769e-05  \n",
       "122088  population   Q702842  5.604656e-05  \n",
       "117129        area   Q702842  1.395731e-12  \n",
       "223939        area  Q1017324  2.068966e-11  \n",
       "...            ...       ...           ...  \n",
       "159470        area  Q6784672  1.314122e-11  \n",
       "215228        area  Q8452914  6.085990e-12  \n",
       "56507   population  Q8452914  4.974963e-06  \n",
       "31531         area   Q548611  2.591970e-10  \n",
       "6381    population   Q548611  2.837436e-05  \n",
       "\n",
       "[34558 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri_data.iloc[attri_data[(attri_data['a'].isin(['P2046','P1082']))].name_e.index,:].sort_values('name_e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>a</th>\n",
       "      <th>v</th>\n",
       "      <th>name_e</th>\n",
       "      <th>name_a</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>minmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>Q680614</td>\n",
       "      <td>P2048</td>\n",
       "      <td>259.0000</td>\n",
       "      <td>30 Rockefeller Plaza</td>\n",
       "      <td>height</td>\n",
       "      <td>Q11303</td>\n",
       "      <td>2.654661e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>Q11208</td>\n",
       "      <td>P2048</td>\n",
       "      <td>21.6408</td>\n",
       "      <td>The Pentagon</td>\n",
       "      <td>height</td>\n",
       "      <td>Q7540126</td>\n",
       "      <td>2.210873e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>Q125543</td>\n",
       "      <td>P2048</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>Bronx‚ÄìWhitestone Bridge</td>\n",
       "      <td>height</td>\n",
       "      <td>Q7814330</td>\n",
       "      <td>4.605823e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11017</th>\n",
       "      <td>Q737945</td>\n",
       "      <td>P2048</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>Jeddah Tower</td>\n",
       "      <td>height</td>\n",
       "      <td>Q11303</td>\n",
       "      <td>1.025192e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14958</th>\n",
       "      <td>Q204871</td>\n",
       "      <td>P2048</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Charles Bridge</td>\n",
       "      <td>height</td>\n",
       "      <td>Q79007</td>\n",
       "      <td>1.324957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17942</th>\n",
       "      <td>Q21028308</td>\n",
       "      <td>P2048</td>\n",
       "      <td>29.2608</td>\n",
       "      <td>O'Neill House Office Building</td>\n",
       "      <td>height</td>\n",
       "      <td>Q6692780</td>\n",
       "      <td>2.992129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18389</th>\n",
       "      <td>Q572887</td>\n",
       "      <td>P2048</td>\n",
       "      <td>199.5100</td>\n",
       "      <td>8 Canada Square</td>\n",
       "      <td>height</td>\n",
       "      <td>Q11303</td>\n",
       "      <td>2.044728e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23151</th>\n",
       "      <td>Q4006202</td>\n",
       "      <td>P2048</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>Red Cross with Imperial Portraits</td>\n",
       "      <td>height</td>\n",
       "      <td>Q331225</td>\n",
       "      <td>-1.025271e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               e      a          v                             name_e  name_a  \\\n",
       "2273     Q680614  P2048   259.0000               30 Rockefeller Plaza  height   \n",
       "4993      Q11208  P2048    21.6408                       The Pentagon  height   \n",
       "7537     Q125543  P2048    45.0000            Bronx‚ÄìWhitestone Bridge  height   \n",
       "11017    Q737945  P2048  1000.0000                       Jeddah Tower  height   \n",
       "14958    Q204871  P2048    13.0000                     Charles Bridge  height   \n",
       "17942  Q21028308  P2048    29.2608      O'Neill House Office Building  height   \n",
       "18389    Q572887  P2048   199.5100                    8 Canada Square  height   \n",
       "23151   Q4006202  P2048     0.0760  Red Cross with Imperial Portraits  height   \n",
       "\n",
       "       ent_type        minmax  \n",
       "2273     Q11303  2.654661e-02  \n",
       "4993   Q7540126  2.210873e-03  \n",
       "7537   Q7814330  4.605823e-03  \n",
       "11017    Q11303  1.025192e-01  \n",
       "14958    Q79007  1.324957e-03  \n",
       "17942  Q6692780  2.992129e-03  \n",
       "18389    Q11303  2.044728e-02  \n",
       "23151   Q331225 -1.025271e-07  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri_data_valid[(attri_data_valid['a']=='P2048') & (attri_data_valid['ent_type']!='Q5')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ÊúâË≥áÊñôÊúâÁº∫Êºè\n",
    "# num_lit[660][gdp],num_lit[660][gdp_per]*num_lit[660][pop_idx]\n",
    "# num_lit[660][gdp],num_lit[660][gdp_per],num_lit[660][pop_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÂÅöx_list under principle:\n",
    "## 1.ÂÖàÁ¢∫ÂÆöÊúâtrueË≥áÊñô: entÁöÑvarÊúâÂÄº\n",
    "## 2.ÂèñÂÖ∂‰ªñÁöÑÁâπÂæµ: var‰ª•Â§ñÁöÑÂÄºÂ≠òÂà∞inner_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner_x_list[-1]ÊòØtrueÔºåx_listÊòØÊúâvarÊúâÂÄºÁöÑÁµÑÔºålen(x_list)ÊòØÊúâÂπæÁµÑËÆäÊï∏ÊúâÂÄº\n",
    "# normalized or non-normalized\n",
    "x_list=[]\n",
    "\n",
    "for i, ent in enumerate(num_lit):\n",
    "    if ent[date_of_death] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        inner_x_list=[]\n",
    "\n",
    "        for j in range(len(ent)):\n",
    "            inner_x_list.append(ent[j])     \n",
    "        inner_x_list.append(i)\n",
    "        x_list.append(inner_x_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ÈÅéÁ®ã\n",
    "def create_x_list(var_idx,num_lit):\n",
    "    x_list=[]\n",
    "\n",
    "    for i, ent in enumerate(num_lit):\n",
    "        if ent[var_idx] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            inner_x_list=[]\n",
    "\n",
    "            for j in range(len(ent)):\n",
    "#                 if j == var2_idx and ent[j]==0:\n",
    "#                     #Â¶ÇÊûúÁÇ∫0ÔºåË£ú‰∏≠‰ΩçÊï∏\n",
    "#                     inner_x_list.append(1)\n",
    "#                 else:\n",
    "                inner_x_list.append(ent[j])\n",
    "            inner_x_list.append(i)\n",
    "            x_list.append(inner_x_list)\n",
    "    return x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list =create_x_list(date_of_birth,num_lit)\n",
    "x_list_valid=create_x_list(date_of_birth,num_lit_valid)\n",
    "df_train =pd.DataFrame(x_list)\n",
    "df_valid = pd.DataFrame(x_list_valid)\n",
    "# Âà™ÊéâÂÖ®ÁÇ∫0ÂÄºÁöÑfeature\n",
    "df_train=df_train.loc[:,(df_train!=0).any(axis=0)]\n",
    "cols = [i for i in df_train.columns if i != date_of_birth]\n",
    "y_train = df_train.loc[:,date_of_birth].values\n",
    "y_valid = df_valid.loc[:,date_of_birth].values\n",
    "\n",
    "x_train = df_train[cols]\n",
    "x_valid = df_valid[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>30</th>\n",
       "      <th>38</th>\n",
       "      <th>40</th>\n",
       "      <th>48</th>\n",
       "      <th>58</th>\n",
       "      <th>63</th>\n",
       "      <th>66</th>\n",
       "      <th>73</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.914589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.254395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.986435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12743 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1           5    6       7       9    12      15     16     19  \\\n",
       "0      0.0  0.0   83.914589  0.0     0.0  1924.0  0.0     0.0  122.0  107.0   \n",
       "1      0.0  0.0   95.254395  0.0     0.0  1967.0  0.0  1210.0  201.0    0.0   \n",
       "2      0.0  0.0    0.000000  0.0     0.0  1937.0  0.0     0.0    0.0    0.0   \n",
       "3      0.0  0.0    0.000000  0.0  1928.0  1908.0  0.0     0.0    0.0    0.0   \n",
       "4      0.0  0.0    0.000000  0.0     0.0   960.0  0.0     0.0    0.0    0.0   \n",
       "...    ...  ...         ...  ...     ...     ...  ...     ...    ...    ...   \n",
       "12738  0.0  0.0  100.000000  0.0     0.0  1973.0  0.0   361.0    0.0   16.0   \n",
       "12739  0.0  0.0   92.986435  0.0     0.0  1982.0  0.0     0.0    0.0    0.0   \n",
       "12740  0.0  0.0    0.000000  0.0     0.0  1970.0  0.0   127.0   27.0    0.0   \n",
       "12741  0.0  0.0    0.000000  0.0     0.0  1884.0  0.0     0.0    0.0    0.0   \n",
       "12742  0.0  0.0   73.000000  0.0  1989.0  1971.0  0.0     0.0    0.0    0.0   \n",
       "\n",
       "       ...    28      30      38   40   48   58   63   66   73     86  \n",
       "0      ...   0.0     0.0    91.0  0.0  0.0  0.0  0.0  0.0  0.0     38  \n",
       "1      ...  88.0     0.0  1731.0  0.0  0.0  0.0  0.0  0.0  0.0     56  \n",
       "2      ...   0.0     0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    120  \n",
       "3      ...   0.0     0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    125  \n",
       "4      ...   0.0     0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    130  \n",
       "...    ...   ...     ...     ...  ...  ...  ...  ...  ...  ...    ...  \n",
       "12738  ... -20.0     0.0   281.0  0.0  0.0  0.0  0.0  0.0  0.0  47738  \n",
       "12739  ...   0.0     0.0     2.0  0.0  0.0  0.0  0.0  0.0  0.0  47739  \n",
       "12740  ...  -9.0     0.0    90.0  0.0  0.0  0.0  0.0  0.0  0.0  47741  \n",
       "12741  ...   0.0     0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  47746  \n",
       "12742  ...   0.0  2009.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  47797  \n",
       "\n",
       "[12743 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.iloc[:,-1].to_numpy()\n",
    "# x_valid.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_e = torch.LongTensor(x_train.iloc[:,-1].to_numpy())\n",
    "entity_embedding = embedding_e(input_e)*math.sqrt(2./128)\n",
    "input_e_val = torch.LongTensor(x_valid.iloc[:,-1].to_numpy())\n",
    "entity_embedding_val = embedding_e(input_e_val)*math.sqrt(2./128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att=torch.FloatTensor(x_train.iloc[:,0:-1].to_numpy())\n",
    "x_att_val=torch.FloatTensor(x_valid.iloc[:,0:-1].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = torch.cat([x_att,entity_embedding],dim=1)\n",
    "x_valid = torch.cat([x_att_val,entity_embedding_val],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[list(att2idx.keys())[list(att2idx.values()).index(i)] for i in select_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data=pd.DataFrame(x_list,columns=list(range(len(x_list[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_list=list()\n",
    "# for ent2 in num_lit:\n",
    "#     if ent2[gdp] ==0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         y_list.append(ent2[gdp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x_list)):\n",
    "#     inner_x = x_list[i]\n",
    "#     inner_x.append(y_list[i])\n",
    "# x_list.append(inner_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_feat(train_data, valid_data, select_all=True):\n",
    "#     '''Selects useful features to perform regression'''\n",
    "\n",
    "#     sc = StandardScaler()\n",
    "#     train_data = sc.fit_transform(train_data)\n",
    "#     valid_data = sc.transform(valid_data)\n",
    "    \n",
    "#     y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "#     raw_x_train, raw_x_valid = train_data[:,:-1], valid_data[:,:-1]\n",
    "    \n",
    "\n",
    "#     if select_all:\n",
    "#         feat_idx = list(range(raw_x_train.shape[1]))\n",
    "#     else:\n",
    "#         feat_idx = select_feature # TODO: Select suitable feature columns.\n",
    "        \n",
    "#     return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGMTL_Data(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "same_seed(config['seed'])\n",
    "\n",
    "\n",
    "# # train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days) \n",
    "# # test_data size: 1078 x 117 (without last day's positive rate)\n",
    "# train_data, valid_data = x_list_train, x_list_valid\n",
    "# #train_data, valid_data = train_valid_split(x_list, config['valid_ratio'], config['seed'])\n",
    "\n",
    "# # Print out the data size.\n",
    "# print(f\"\"\"train_data size: {train_data.shape} \n",
    "# valid_data size: {valid_data.shape} \"\"\")\n",
    "# # test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "\n",
    "# # Select features\n",
    "# x_train, x_valid, y_train, y_valid = select_feat(train_data, valid_data, config['select_all'])\n",
    "\n",
    "# # Print out the number of features.\n",
    "# print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "train_dataset, valid_dataset = KGMTL_Data(x_train, y_train), \\\n",
    "                                            KGMTL_Data(x_valid, y_valid)\n",
    "\n",
    "print('train_dataset', train_dataset[120])\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.5),\n",
    "#             nn.Linear(64,64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Linear(200, 1),\n",
    "        )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        \n",
    "        return self.criterion(pred, target) + 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39U_XFX6KOoj"
   },
   "source": [
    "# **Preprocess**\n",
    "\n",
    "We have three kinds of datasets:\n",
    "* `train`: for training\n",
    "* `dev`: for validation\n",
    "* `test`: for testing (w/o target value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "loss_record={'train': [], 'dev': [],'mean_train_loss':[],'mean_valid_loss':[]} \n",
    "\n",
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "\n",
    "    # Define your optimization algorithm. \n",
    "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
    "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9, weight_decay=1e-6)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    writer = SummaryWriter() # Writer of tensoboard\n",
    "#     if not os.path.isdir('./models_var'):\n",
    "#         os.mkdir('./models_var') # Create directory of saving models.\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_pbar:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
    "            pred = model(x)   \n",
    "            print(f'-------predict: {pred}, y: {y}----------') \n",
    "\n",
    "            #x_constraint = torch.tensor([(x[i][cols.index(3)]*x[i][cols.index(46)]) for i in range(len(x))])\n",
    "            #x_constraint = torch.tensor([x[i][pop_idx]*x[i][gdp_per] for i in range(len(x))])\n",
    "            #print(x_constraint)\n",
    "            #x_constraint = x_constraint.to(device)\n",
    "            loss = model.criterion(pred, y)\n",
    "            #loss = criterion(pred, y) + criterion(pred, x_constraint)\n",
    "                    #x_constraint = 1000\n",
    "                     \n",
    "            # criterion(pred,x_constraint)\n",
    "                # ((pred-x[0]*x[18])**2) \n",
    "                \n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record[\"train\"].append(loss.detach().item())\n",
    "            \n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "\n",
    "        mean_train_loss = sum(loss_record[\"train\"])/len(loss_record[\"train\"])\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "        loss_record['mean_train_loss'].append(mean_train_loss)\n",
    "\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                # print(f'x: {x}')\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record[\"dev\"].append(loss.item())\n",
    "            \n",
    "        mean_valid_loss = sum(loss_record[\"dev\"])/len(loss_record[\"dev\"])\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "        loss_record['mean_valid_loss'].append(mean_valid_loss)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hSd4Bn3O2PL"
   },
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrxrD3YsN3U2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "def eval_matrics(y_test, y_pred):\n",
    "\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    print('MSE=',MSE)\n",
    "    RMSE =np.sqrt(MSE)\n",
    "    print('RMSE=',RMSE)\n",
    "    MAE= mean_absolute_error(y_test, y_pred)\n",
    "    print('MAE=',MAE)\n",
    "\n",
    "    R2=1-MSE/np.var(y_test)\n",
    "    print(\"R2=\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0pdrhQAO41L"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSBMRFlYN5tB"
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []; y_b=[]\n",
    "    for x,y in tt_set:                            # iterate through the dataloader\n",
    "        x ,y = x.to(device), y.to(device)                          # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())\n",
    "            y_b.append(y.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy().reshape(-1,1)     # concatenate all predictions and convert to a numpy array\n",
    "    y_b= torch.cat(y_b,0).numpy().reshape(-1,1) \n",
    "    table  = np.concatenate((preds, y_b),axis=1)\n",
    "    eval_matrics(y_b,preds)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "#os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': False,   # Whether to use all features.\n",
    "    'n_epochs': 500,                # maximum number of epochs\n",
    "    'batch_size': 32,               # mini-batch size for dataloader\n",
    "    'learning_rate':1e-3,\n",
    "    'early_stop': 15,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': './model_birth_nocon_pretraine.pt' , # your model will be saved here\n",
    "    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j1eOV3TOH-j"
   },
   "source": [
    "# **Load data and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHylSirLP9oh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(input_dim=x_train.shape[1]).to(device)  # Construct model and move to device\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sX2B_zgSOPTJ"
   },
   "source": [
    "# **Start Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrEbUxazQAAZ",
    "outputId": "f4f3bd74-2d97-4275-b69f-6609976b91f9"
   },
   "outputs": [],
   "source": [
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max(loss_record[\"mean_valid_loss\"]),min(loss_record[\"mean_valid_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hsNO9nnXQBvP",
    "outputId": "1626def6-94c7-4a87-9447-d939f827c8eb"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['save_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "3iZTVn5WQFpX",
    "outputId": "a2d5e118-559d-45c6-b644-6792af54663d"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = NeuralNet(input_dim=x_train.shape[1]).to(device)\n",
    "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = test(valid_loader, model, device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(preds,columns=['predict','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim=2200\n",
    "preds=df2['predict']\n",
    "targets=df2['target']\n",
    "figure(figsize=(5, 5))\n",
    "plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "plt.plot([-10, lim], [-10, lim], c='b')\n",
    "plt.xlim(0, lim)\n",
    "plt.ylim(0, lim)\n",
    "plt.xlabel('ground truth value')\n",
    "plt.ylabel('predicted value')\n",
    "plt.title('Ground Truth v.s. Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDP value prediction\n",
    "input: entities's GDP_per, pop and 27 var values, no ent embddings \n",
    "adding gdp_per * pop constraint\n",
    "tried: lambda 0.0075, 0.2, 1000 cannot make any effect\n",
    "tried2: pred<0 cons=1000 it run into some technical isse\n",
    "value: no normalized\n",
    "problem: after one epoch cannot updated\n",
    "result: loss is large but training loss decreased slowly, with constraint no effect\n",
    "reason why: data is small(125), valid features is a lot of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQikz3IPiyPf"
   },
   "source": [
    "# **Testing**\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8cTuQjQQOon",
    "outputId": "6bc5de07-4c5a-4e87-9ae3-d09f539c5f2c"
   },
   "outputs": [],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "preds = test(valid_loader, model, device)  # predict COVID-19 cases with your model\n",
    "print('pred')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tmCwXgpot3t"
   },
   "source": [
    "# **Reference**\n",
    "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
    "Copying or reusing this code is required to specify the original author. \n",
    "\n",
    "E.g.  \n",
    "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb",
     "timestamp": 1656054510646
    }
   ],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "58040a4f1aa4f5275e06049c30a95750b5a145ef4b58852d0762723662f03261"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
